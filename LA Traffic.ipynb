{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71af53f3-af13-4676-b24e-4c06b39c9c67",
   "metadata": {},
   "source": [
    "# Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced5e735-b4d4-48a2-ad59-781b93047c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd1071-ef14-4d89-b44d-cf6d17abf201",
   "metadata": {},
   "source": [
    "# Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0831bfa6-d998-4ae1-92a3-9b677ec5b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "def distance_to_weight(W, sigma2=0.1, epsilon=0.5, gat_version=False):\n",
    "    \"\"\"\"\n",
    "    Given distances between all nodes, convert into a weight matrix\n",
    "    :param W distances\n",
    "    :param sigma2 User configurable parameter to adjust sparsity of matrix\n",
    "    :param epsilon User configurable parameter to adjust sparsity of matrix\n",
    "    :param gat_version If true, use 0/1 weights with self loops. Otherwise, use float\n",
    "    \"\"\"\n",
    "    n = W.shape[0]\n",
    "    W = W / 10000.\n",
    "    W2, W_mask = W * W, np.ones([n, n]) - np.identity(n)\n",
    "    # refer to Eq.10\n",
    "    W = np.exp(-W2 / sigma2) * (np.exp(-W2 / sigma2) >= epsilon) * W_mask\n",
    "\n",
    "    # If using the gat version of this, round to 0/1 and include self loops\n",
    "    if gat_version:\n",
    "        W[W>0] = 1\n",
    "        W += np.identity(n)\n",
    "\n",
    "\n",
    "    return W\n",
    "\n",
    "class TrafficDataset(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    Dataset for Graph Neural Networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, W, root='', transform=None, pre_transform=None):\n",
    "        self.config = config\n",
    "        self.W = W\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices, self.n_node, self.mean, self.std_dev = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [os.path.join(self.raw_dir, 'PeMSD7_V_228.csv')]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['./data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        copyfile('./dataset/PeMSD7_V_228.csv', os.path.join(self.raw_dir, 'PeMSD7_V_228.csv'))\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Process the raw datasets into saved .pt dataset for later use.\n",
    "        Note that any self.fields here wont exist if loading straight from the .pt file\n",
    "        \"\"\"\n",
    "        # Data Preprocessing and loading\n",
    "        data = pd.read_csv(self.raw_file_names[0], header=None).values\n",
    "        # Technically using the validation and test datasets here, but it's fine, would normally get the\n",
    "        # mean and std_dev from a large dataset\n",
    "        mean =  np.mean(data)\n",
    "        std_dev = np.std(data)\n",
    "        data = z_score(data, np.mean(data), np.std(data))\n",
    "        \n",
    "        _, n_node = data.shape\n",
    "        n_window = self.config['N_PRED'] + self.config['N_HIST']\n",
    "\n",
    "        # manipulate nxn matrix into 2xnum_edges\n",
    "        edge_index = torch.zeros((2, n_node**2), dtype=torch.long)\n",
    "        # create an edge_attr matrix with our weights  (num_edges x 1) --> our edge features are dim 1\n",
    "        edge_attr = torch.zeros((n_node**2, 1))\n",
    "        num_edges = 0\n",
    "        for i in range(n_node):\n",
    "            for j in range(n_node):\n",
    "                if self.W[i, j] != 0.:\n",
    "                    edge_index[0, num_edges] = i\n",
    "                    edge_index[1, num_edges] = j\n",
    "                    edge_attr[num_edges] = self.W[i, j]\n",
    "                    num_edges += 1\n",
    "\n",
    "        # using resize_ to just keep the first num_edges entries\n",
    "        edge_index = edge_index.resize_(2, num_edges)\n",
    "        edge_attr = edge_attr.resize_(num_edges, 1)\n",
    "\n",
    "        sequences = []\n",
    "        # T x F x N\n",
    "        for i in range(self.config['N_DAYS']):\n",
    "            for j in range(self.config['N_SLOT']):\n",
    "                # for each time point construct a different graph with data object\n",
    "                # Docs here: https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data\n",
    "                g = Data()\n",
    "                g.__num_nodes__ = n_node\n",
    "\n",
    "                g.edge_index = edge_index\n",
    "                g.edge_attr  = edge_attr\n",
    "\n",
    "                # (F,N) switched to (N,F)\n",
    "                sta = i * self.config['N_DAY_SLOT'] + j\n",
    "                end = sta + n_window\n",
    "                # [21, 228]\n",
    "                full_window = np.swapaxes(data[sta:end, :], 0, 1)\n",
    "                g.x = torch.FloatTensor(full_window[:, 0:self.config['N_HIST']])\n",
    "                g.y = torch.FloatTensor(full_window[:, self.config['N_HIST']::])\n",
    "                sequences += [g]\n",
    "\n",
    "        # Make the actual dataset\n",
    "        data, slices = self.collate(sequences)\n",
    "\n",
    "        torch.save((data, slices, n_node, mean, std_dev), self.processed_paths[0])\n",
    "\n",
    "def get_splits(dataset: TrafficDataset, n_slot, splits):\n",
    "    \"\"\"\n",
    "    Given the data, split it into random subsets of train, val, and test as given by splits\n",
    "    :param dataset: TrafficDataset object to split\n",
    "    :param n_slot: Number of possible sliding windows in a day\n",
    "    :param splits: (train, val, test) ratios\n",
    "    \"\"\"\n",
    "    split_train, split_val, _ = splits\n",
    "    i = n_slot*split_train\n",
    "    j = n_slot*split_val\n",
    "    train = dataset[:i]\n",
    "    val = dataset[i:i+j]\n",
    "    test = dataset[i+j:]\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b1c66-3e66-4e67-98a7-1b0a848f5489",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9c2c429-ba12-4dec-97b0-5e28c0d63270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "class ST_GAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-Temporal Graph Attention Network as presented in https://ieeexplore.ieee.org/document/8903252\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, n_nodes, heads=8, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the ST-GAT model\n",
    "        :param in_channels Number of input channels\n",
    "        :param out_channels Number of output channels\n",
    "        :param n_nodes Number of nodes in the graph\n",
    "        :param heads Number of attention heads to use in graph\n",
    "        :param dropout Dropout probability on output of Graph Attention Network\n",
    "        \"\"\"\n",
    "        super(ST_GAT, self).__init__()\n",
    "        self.n_pred = out_channels\n",
    "        self.heads = heads\n",
    "        self.dropout = dropout\n",
    "        self.n_nodes = n_nodes\n",
    "\n",
    "        self.n_preds = 9\n",
    "        lstm1_hidden_size = 32\n",
    "        lstm2_hidden_size = 128\n",
    "\n",
    "        # single graph attentional layer with 8 attention heads\n",
    "        self.gat = GATConv(in_channels=in_channels, out_channels=in_channels,\n",
    "            heads=heads, dropout=0, concat=False)\n",
    "\n",
    "        # add two LSTM layers\n",
    "        self.lstm1 = torch.nn.LSTM(input_size=self.n_nodes, hidden_size=lstm1_hidden_size, num_layers=1)\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                torch.nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "        self.lstm2 = torch.nn.LSTM(input_size=lstm1_hidden_size, hidden_size=lstm2_hidden_size, num_layers=1)\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                torch.nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "        # fully-connected neural network\n",
    "        self.linear = torch.nn.Linear(lstm2_hidden_size, self.n_nodes*self.n_pred)\n",
    "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "\n",
    "    def forward(self, data, device):\n",
    "        \"\"\"\n",
    "        Forward pass of the ST-GAT model\n",
    "        :param data Data to make a pass on\n",
    "        :param device Device to operate on\n",
    "        \"\"\"\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        print(x)\n",
    "        # apply dropout\n",
    "        if device == 'cpu':\n",
    "            x = torch.FloatTensor(x)\n",
    "        else:\n",
    "            x = torch.cuda.FloatTensor(x)\n",
    "\n",
    "        # gat layer: output of gat: [11400, 12]\n",
    "        x = self.gat(x, edge_index)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        # RNN: 2 LSTM\n",
    "        # [batchsize*n_nodes, seq_length] -> [batch_size, n_nodes, seq_length]\n",
    "        batch_size = data.num_graphs\n",
    "        n_node = int(data.num_nodes/batch_size)\n",
    "        x = torch.reshape(x, (batch_size, n_node, data.num_features))\n",
    "        # for lstm: x should be (seq_length, batch_size, n_nodes)\n",
    "        # sequence length = 12, batch_size = 50, n_node = 228\n",
    "        x = torch.movedim(x, 2, 0)\n",
    "        # [12, 50, 228] -> [12, 50, 32]\n",
    "        x, _ = self.lstm1(x)\n",
    "        # [12, 50, 32] -> [12, 50, 128]\n",
    "        x, _ = self.lstm2(x)\n",
    "\n",
    "        # Output contains h_t for each timestep, only the last one has all input's accounted for\n",
    "        # [12, 50, 128] -> [50, 128]\n",
    "        x = torch.squeeze(x[-1, :, :])\n",
    "        # [50, 128] -> [50, 228*9]\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # Now reshape into final output\n",
    "        s = x.shape\n",
    "        # [50, 228*9] -> [50, 228, 9]\n",
    "        x = torch.reshape(x, (s[0], self.n_nodes, self.n_pred))\n",
    "        # [50, 228, 9] ->  [11400, 9]\n",
    "        x = torch.reshape(x, (s[0]*self.n_nodes, self.n_pred))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef9455-a23f-4bb9-b3c7-ac3af530c2c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Train and Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3749b6a1-5e03-47c5-8f30-23df1a852d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, device, dataloader, type=''):\n",
    "    \"\"\"\n",
    "    Evaluation function to evaluate model on data\n",
    "    :param model Model to evaluate\n",
    "    :param device Device to evaluate on\n",
    "    :param dataloader Data loader\n",
    "    :param type Name of evaluation type, e.g. Train/Val/Test\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    mae = 0\n",
    "    rmse = 0\n",
    "    mape = 0\n",
    "    n = 0\n",
    "\n",
    "    # Evaluate model on all data\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch, device)\n",
    "            truth = batch.y.view(pred.shape)\n",
    "            if i == 0:\n",
    "                y_pred = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
    "                y_truth = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
    "                print(y_pred.shape)\n",
    "            truth = un_z_score(truth, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
    "            pred = un_z_score(pred, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
    "            y_pred[i, :pred.shape[0], :] = pred\n",
    "            y_truth[i, :pred.shape[0], :] = truth\n",
    "    \n",
    "            rmse += RMSE(truth, pred)\n",
    "            mae += MAE(truth, pred)\n",
    "            mape += MAPE(truth, pred)\n",
    "            n += 1\n",
    "    rmse, mae, mape = rmse / n, mae / n, mape / n\n",
    "    print(f'{type}, MAE: {mae}, RMSE: {rmse}, MAPE: {mape}')  \n",
    "    #get the average score for each metric in each batch\n",
    "    return rmse, mae, mape, y_pred, y_truth\n",
    "\n",
    "def train(model, device, dataloader, optimizer, loss_fn, epoch):\n",
    "    \"\"\"\n",
    "    Evaluation function to evaluate model on data\n",
    "    :param model Model to evaluate\n",
    "    :param device Device to evaluate on\n",
    "    :param dataloader Data loader\n",
    "    :param optimizer Optimizer to use\n",
    "    :param loss_fn Loss function\n",
    "    :param epoch Current epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for _, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = torch.squeeze(model(batch, device))\n",
    "        loss = loss_fn()(y_pred.float(), torch.squeeze(batch.y).float())\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "632a2b97-1df4-426f-b620-373128bc65ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def z_score(x, mean, std):\n",
    "    \"\"\"\n",
    "    Z-score normalization function: $z = (X - \\mu) / \\sigma $,\n",
    "    where z is the z-score, X is the value of the element,\n",
    "    $\\mu$ is the population mean, and $\\sigma$ is the standard deviation.\n",
    "    :param x: torch array, input array to be normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    :return: torch array, z-score normalized array.\n",
    "    \"\"\"\n",
    "    return (x - mean) / std\n",
    "\n",
    "def un_z_score(x_normed, mean, std):\n",
    "    \"\"\"\n",
    "    Undo the Z-score calculation\n",
    "    :param x_normed: torch array, input array to be un-normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    \"\"\"\n",
    "    return x_normed * std  + mean\n",
    "\n",
    "\n",
    "def MAPE(v, v_):\n",
    "    \"\"\"\n",
    "    Mean absolute percentage error, given as a % (e.g. 99 -> 99%)\n",
    "    :param v: torch array, ground truth.\n",
    "    :param v_: torch array, prediction.\n",
    "    :return: torch scalar, MAPE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs((v_ - v)) /(v + 1e-15) * 100)\n",
    "\n",
    "\n",
    "def RMSE(v, v_):\n",
    "    \"\"\"\n",
    "    Mean squared error.\n",
    "    :param v: torch array, ground truth.\n",
    "    :param v_: torch array, prediction.\n",
    "    :return: torch scalar, RMSE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    return torch.sqrt(torch.mean((v_ - v) ** 2))\n",
    "\n",
    "\n",
    "def MAE(v, v_):\n",
    "    \"\"\"\n",
    "    Mean absolute error.\n",
    "    :param v: torch array, ground truth.\n",
    "    :param v_: torch array, prediction.\n",
    "    :return: torch scalar, MAE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(v_ - v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b850bea7-9acf-44db-8e15-bc9291a47e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Make a tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def model_train(train_dataloader, val_dataloader, config, device):\n",
    "    \"\"\"\n",
    "    Train the ST-GAT model. Evaluate on validation dataset as you go.\n",
    "    :param train_dataloader Data loader of training dataset\n",
    "    :param val_dataloader Dataloader of val dataset\n",
    "    :param config configuration to use\n",
    "    :param device Device to evaluate on\n",
    "    \"\"\"\n",
    "\n",
    "    # Make the model. Each datapoint in the graph is 228x12: N x F (N = # nodes, F = time window)\n",
    "    model = ST_GAT(in_channels=config['N_HIST'], out_channels=config['N_PRED'], n_nodes=config['N_NODE'], dropout=config['DROPOUT']) \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['INITIAL_LR'], weight_decay=config['WEIGHT_DECAY'])\n",
    "    loss_fn = torch.nn.MSELoss\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # For every epoch, train the model on training dataset. Evaluate model on validation dataset\n",
    "    for epoch in range(config['EPOCHS']):\n",
    "        loss = train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n",
    "        print(f\"Loss: {loss:.3f}\")\n",
    "        if epoch % 5 == 0:\n",
    "            train_mae, train_rmse, train_mape, _, _ = eval(model, device, train_dataloader, 'Train')\n",
    "            val_mae, val_rmse, val_mape, _, _ = eval(model, device, val_dataloader, 'Valid')\n",
    "            writer.add_scalar(f\"MAE/train\", train_mae, epoch)\n",
    "            writer.add_scalar(f\"RMSE/train\", train_rmse, epoch)\n",
    "            writer.add_scalar(f\"MAPE/train\", train_mape, epoch)\n",
    "            writer.add_scalar(f\"MAE/val\", val_mae, epoch)\n",
    "            writer.add_scalar(f\"RMSE/val\", val_rmse, epoch)\n",
    "            writer.add_scalar(f\"MAPE/val\", val_mape, epoch)\n",
    "\n",
    "    writer.flush()\n",
    "    # Save the model\n",
    "    timestr = time.strftime(\"%m-%d-%H%M%S\")\n",
    "    torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": loss,\n",
    "            }, os.path.join(config[\"CHECKPOINT_DIR\"], f\"model_{timestr}.pt\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_test(model, test_dataloader, device, config):\n",
    "    \"\"\"\n",
    "    Test the ST-GAT model\n",
    "    :param test_dataloader Data loader of test dataset\n",
    "    :param device Device to evaluate on\n",
    "    \"\"\"\n",
    "    _, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d68803a-e07b-4ab0-baa1-a3ebdc83d57f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a16779-738e-4214-a02a-d8f8a676d719",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce06b75a-0afe-44cf-bb5c-5aaf9c2e68e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Constant config to use throughout\n",
    "config = {\n",
    "    'BATCH_SIZE': 50,\n",
    "    'EPOCHS': 6, # 60 default\n",
    "    'WEIGHT_DECAY': 5e-5,\n",
    "    'INITIAL_LR': 3e-4,\n",
    "    'CHECKPOINT_DIR': './runs',\n",
    "    'N_PRED': 9,\n",
    "    'N_HIST': 12,\n",
    "    'DROPOUT': 0.2,\n",
    "    # number of possible 5 minute measurements per day\n",
    "    'N_DAY_SLOT': 288,\n",
    "    # number of days worth of data in the dataset\n",
    "    'N_DAYS': 44,\n",
    "    # If false, use GCN paper weight matrix, if true, use GAT paper weight matrix\n",
    "    'USE_GAT_WEIGHTS': True,\n",
    "    'N_NODE': 228,\n",
    "}\n",
    "# Number of possible windows in a day\n",
    "config['N_SLOT']= config['N_DAY_SLOT'] - (config['N_PRED']+config['N_HIST']) + 1\n",
    "\n",
    "# Load the weight and dataset dataset\n",
    "distances = pd.read_csv('./dataset/PeMSD7_W_228.csv', header=None).values\n",
    "W = distance_to_weight(distances, gat_version=config['USE_GAT_WEIGHTS'])\n",
    "dataset = TrafficDataset(config, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e76bc79f-403d-4240-bc94-37d36bee60a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "# total of 44 days in the dataset, use 34 for training, 5 for val, 5 for test\n",
    "d_train, d_val, d_test = get_splits(dataset, config['N_SLOT'], (34, 5, 5))\n",
    "train_dataloader = DataLoader(d_train, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
    "val_dataloader = DataLoader(d_val, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
    "test_dataloader = DataLoader(d_test, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "# Get gpu if you can\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Configure and train model\n",
    "config['N_NODE'] = dataset.n_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f415457-d431-4fad-b22d-bbcf136760d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/183 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8315,  0.8685,  0.8389,  ...,  0.8389,  0.9056,  0.7573],\n",
      "        [ 1.0985,  0.5867,  0.8092,  ...,  0.7795,  0.7350,  0.8982],\n",
      "        [-0.1327, -0.1179,  0.0676,  ...,  0.0453,  0.0898,  0.2307],\n",
      "        ...,\n",
      "        [ 0.2826,  0.3271,  0.2604,  ...,  0.1936,  0.2085,  0.1862],\n",
      "        [ 0.0972,  0.1343,  0.1417,  ...,  0.0231,  0.0898,  0.1862],\n",
      "        [-0.1179,  0.1343,  0.1936,  ...,  0.4903,  0.5496,  0.5645]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 2/183 [00:00<00:37,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2168, -2.4022, -2.4838,  ..., -2.8101, -2.5653, -2.6321],\n",
      "        [ 0.9724,  0.8315,  0.9279,  ...,  0.7425,  0.7499,  0.5719],\n",
      "        [-1.9794, -2.2909, -2.3058,  ..., -1.5493, -1.2749, -1.3119],\n",
      "        ...,\n",
      "        [ 0.6609,  0.6757,  0.6980,  ...,  0.7054,  0.8018,  0.8908],\n",
      "        [ 0.6312,  0.6831,  0.7276,  ...,  0.6831,  0.6831,  0.6238],\n",
      "        [ 0.7202,  0.7128,  0.6386,  ...,  0.7054,  0.7054,  0.7202]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.0082, -0.0066, -0.0734,  ...,  0.0453,  0.1195,  0.0972],\n",
      "        [ 0.8982,  0.9205,  0.7202,  ...,  1.2320,  0.9130,  1.1281],\n",
      "        [ 0.7128,  0.6905,  0.6905,  ...,  0.4532,  0.4310,  0.5496],\n",
      "        ...,\n",
      "        [-1.0079, -1.0301, -0.9634,  ..., -0.1698, -0.1772, -0.3107],\n",
      "        [-3.0623, -2.7433, -2.7953,  ..., -1.5493, -1.6902, -2.1129],\n",
      "        [ 0.0156, -0.0659, -0.1846,  ...,  0.1714,  0.2752,  0.2530]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 3/183 [00:00<00:32,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11400, 9])\n",
      "tensor([[-2.2835, -1.5196, -1.8237,  ..., -1.2749, -0.8892, -0.4219],\n",
      "        [-2.7063, -3.0623, -3.2773,  ..., -2.2464, -2.6173, -2.3132],\n",
      "        [ 0.7870,  0.8463,  0.9056,  ...,  0.8166,  0.8760,  0.8463],\n",
      "        ...,\n",
      "        [ 0.0750,  0.0082, -0.0437,  ...,  0.0156,  0.0601, -0.0066],\n",
      "        [ 0.1417, -0.0066,  0.0379,  ...,  0.0156, -0.0066,  0.0082],\n",
      "        [ 0.2975,  0.2011,  0.2530,  ..., -0.2736, -0.6370, -0.6741]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 5/183 [00:00<00:26,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9501,  1.2171,  1.2023,  ...,  0.4235,  0.4235,  0.3642],\n",
      "        [ 0.7870,  0.6386,  0.7350,  ...,  0.6831,  0.5867,  0.5200],\n",
      "        [ 0.9724,  1.0391,  1.0391,  ..., -0.5777, -0.5703, -1.1265],\n",
      "        ...,\n",
      "        [ 0.6609,  0.6831,  0.7350,  ...,  0.6683,  0.5348,  0.6905],\n",
      "        [ 0.6460,  0.7128,  0.7276,  ...,  0.5645,  0.4310,  0.6831],\n",
      "        [ 0.4087,  0.4013,  0.4310,  ...,  0.4977,  0.5051,  0.4755]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-2.1055, -1.2971, -0.4887,  ...,  0.6683,  0.5793,  0.4235],\n",
      "        [ 0.3049,  0.3865,  0.3271,  ...,  0.3865,  0.2381,  0.2381],\n",
      "        [-1.7718, -1.7495, -1.7273,  ..., -0.6889, -0.6815, -0.8966],\n",
      "        ...,\n",
      "        [ 0.0750,  0.0453,  0.1046,  ...,  0.1195,  0.2307,  0.2455],\n",
      "        [ 0.2826,  0.2678,  0.2233,  ...,  0.2900,  0.3865,  0.3049],\n",
      "        [-0.8150, -0.5184, -0.2810,  ..., -0.2588, -0.2143, -0.0437]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   4%|▍         | 7/183 [00:01<00:26,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.3505e-01,  7.7213e-01,  8.0179e-01,  ...,  5.8671e-01,\n",
      "          6.6830e-01,  8.2404e-01],\n",
      "        [ 5.7930e-01,  6.1638e-01,  1.0910e+00,  ...,  4.0872e-01,\n",
      "          4.2355e-01,  2.6038e-01],\n",
      "        [ 6.7571e-01,  4.5321e-01,  3.9388e-01,  ...,  2.1588e-01,\n",
      "          1.3430e-01,  1.5655e-01],\n",
      "        ...,\n",
      "        [-6.5947e-02,  1.0463e-01,  3.7885e-02,  ..., -4.3697e-02,\n",
      "          4.5302e-02, -8.0780e-02],\n",
      "        [ 8.9801e-02,  4.5302e-02,  7.4968e-02,  ...,  1.5635e-02,\n",
      "          4.5302e-02,  8.0218e-04],\n",
      "        [ 2.3072e-01,  2.6038e-01,  1.9363e-01,  ...,  2.3072e-01,\n",
      "          2.3813e-01,  3.2713e-01]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[0.1491, 0.0601, 0.1269,  ..., 0.2011, 0.3271, 0.3271],\n",
      "        [0.7647, 0.7573, 0.6757,  ..., 0.9427, 1.3358, 1.0836],\n",
      "        [1.0540, 1.2394, 1.1133,  ..., 0.4606, 0.7721, 0.7499],\n",
      "        ...,\n",
      "        [0.6535, 0.5941, 0.5941,  ..., 0.7499, 0.7944, 0.6757],\n",
      "        [0.6535, 0.7128, 0.6609,  ..., 0.8611, 0.8092, 0.7128],\n",
      "        [0.2381, 0.2307, 0.2455,  ..., 0.1121, 0.1195, 0.0898]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5%|▍         | 9/183 [00:01<00:24,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8620, -3.0845, -2.8472,  ...,  0.1862,  0.4087,  0.4310],\n",
      "        [-3.5147, -3.3663, -3.5147,  ..., -3.3070, -3.3441, -3.2403],\n",
      "        [ 0.7054,  0.6905,  0.7425,  ...,  0.8092,  0.8315,  0.8018],\n",
      "        ...,\n",
      "        [ 0.3420,  0.3865,  0.3271,  ...,  0.4755,  0.4829,  0.4310],\n",
      "        [ 0.2530,  0.2678,  0.2900,  ...,  0.5051,  0.5422,  0.5200],\n",
      "        [-0.6222, -0.5480, -0.5035,  ..., -0.6519, -0.5035, -0.6074]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.2900,  0.0676,  0.3049,  ..., -0.0808, -0.2959, -0.2736],\n",
      "        [-2.2019, -0.7409,  0.0231,  ...,  0.4384,  0.4310,  0.4903],\n",
      "        [ 0.1195, -0.0808, -0.1030,  ..., -1.3787, -1.6531, -1.7273],\n",
      "        ...,\n",
      "        [ 0.2085,  0.1788,  0.2530,  ...,  0.1491,  0.0972,  0.1417],\n",
      "        [ 0.2900,  0.2455,  0.2975,  ...,  0.1566,  0.2381,  0.2604],\n",
      "        [ 0.1862,  0.3271,  0.4977,  ...,  0.6609,  0.5422,  0.5422]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6%|▌         | 11/183 [00:01<00:24,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1195,  0.0231,  0.0527,  ...,  0.0824,  0.0750, -0.1179],\n",
      "        [ 0.6831,  0.6312,  0.5570,  ...,  0.9946,  0.8685,  0.9946],\n",
      "        [ 0.4532,  0.5274,  0.6980,  ...,  0.5348,  0.5422,  0.4680],\n",
      "        ...,\n",
      "        [ 0.4384,  0.4977,  0.5719,  ...,  0.3790,  0.3642,  0.4310],\n",
      "        [ 0.3123,  0.3865,  0.3790,  ...,  0.1788,  0.1788,  0.1714],\n",
      "        [ 0.4977,  0.4087,  0.3345,  ...,  0.2900,  0.3790,  0.3865]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.5496,  0.5941,  0.5200,  ..., -1.4084, -1.9275, -2.2835],\n",
      "        [ 0.6683,  0.5645,  0.7054,  ...,  0.6386,  0.6460,  0.7425],\n",
      "        [-1.2600, -1.5048, -1.6457,  ..., -1.4380, -1.6383, -1.2749],\n",
      "        ...,\n",
      "        [ 0.6683,  0.5793,  0.5719,  ...,  0.8685,  0.8463,  0.8389],\n",
      "        [ 0.6460,  0.5793,  0.6905,  ...,  0.8908,  0.8389,  0.8240],\n",
      "        [ 0.8018,  0.6535,  0.6905,  ...,  0.7573,  0.7128,  0.7350]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   7%|▋         | 13/183 [00:01<00:23,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3577, -2.2983, -2.5357,  ..., -2.5728, -0.4442, -1.1636],\n",
      "        [ 0.4903,  0.5422,  0.4235,  ..., -2.1648, -2.7804, -2.8249],\n",
      "        [-0.0956,  0.0453,  0.1788,  ..., -0.2514, -0.1624, -0.1475],\n",
      "        ...,\n",
      "        [ 0.6535,  0.6164,  0.4755,  ...,  0.7350,  0.8315,  0.9353],\n",
      "        [ 0.5274,  0.3790,  0.4458,  ...,  0.6609,  0.7350,  0.9279],\n",
      "        [ 0.7944,  0.7425,  0.8463,  ...,  0.8834,  0.7795,  0.6757]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[0.7499, 0.9205, 0.8389,  ..., 0.7721, 1.0020, 0.7054],\n",
      "        [1.2245, 1.1133, 1.1059,  ..., 0.8092, 1.0762, 1.0391],\n",
      "        [0.4087, 0.4013, 0.1121,  ..., 0.6831, 0.5793, 0.5200],\n",
      "        ...,\n",
      "        [0.3345, 0.2011, 0.3197,  ..., 0.5645, 0.5719, 0.6905],\n",
      "        [0.1343, 0.1343, 0.1343,  ..., 0.4977, 0.4829, 0.5793],\n",
      "        [0.2975, 0.2975, 0.3568,  ..., 0.3939, 0.4087, 0.3790]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8%|▊         | 14/183 [00:02<00:24,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11400, 9])\n",
      "tensor([[-2.9362e+00, -2.7953e+00, -2.8768e+00,  ..., -2.8323e+00,\n",
      "         -2.8101e+00, -2.8398e+00],\n",
      "        [ 9.1304e-01,  8.7596e-01,  7.4988e-01,  ...,  6.5346e-01,\n",
      "          5.0513e-01,  4.9771e-01],\n",
      "        [-1.9127e+00, -2.0388e+00, -2.3280e+00,  ..., -4.2936e-01,\n",
      "         -1.4011e-01, -7.3364e-02],\n",
      "        ...,\n",
      "        [-1.1786e-01, -1.4011e-01, -1.7720e-01,  ..., -1.6978e-01,\n",
      "         -2.3653e-01, -1.6236e-01],\n",
      "        [-1.2528e-01, -1.2528e-01, -1.2528e-01,  ...,  3.0469e-02,\n",
      "          8.0218e-04,  1.5635e-02],\n",
      "        [-1.0303e-01, -3.6281e-02, -7.3364e-02,  ..., -2.8103e-01,\n",
      "         -3.1069e-01, -3.1069e-01]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9%|▊         | 16/183 [00:02<00:23,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0762, 1.0465, 1.1281,  ..., 0.7350, 0.8611, 0.9205],\n",
      "        [0.8315, 0.8315, 0.8240,  ..., 0.7499, 0.7350, 0.8315],\n",
      "        [0.6831, 0.6609, 0.6980,  ..., 0.6683, 0.7647, 0.6312],\n",
      "        ...,\n",
      "        [0.9279, 0.8685, 0.8463,  ..., 0.5274, 0.4977, 0.4829],\n",
      "        [0.8982, 0.8908, 0.8389,  ..., 0.6312, 0.6312, 0.5645],\n",
      "        [0.7128, 0.7573, 0.7128,  ..., 0.3420, 0.2752, 0.2307]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.2233,  0.1936, -0.0437,  ...,  0.1343, -0.1104,  0.0231],\n",
      "        [ 0.8760,  1.0169,  0.8611,  ...,  0.9056,  0.8611,  0.8092],\n",
      "        [ 0.6905,  0.6609,  0.8685,  ...,  1.1133,  1.0836,  1.0688],\n",
      "        ...,\n",
      "        [ 0.6757,  0.6609,  0.3568,  ...,  0.4829,  0.5200,  0.7647],\n",
      "        [ 0.6312,  0.5941,  0.5867,  ...,  0.5200,  0.6609,  0.5867],\n",
      "        [ 0.7944,  0.8463,  0.8240,  ...,  0.8240,  0.8092,  0.8611]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|▉         | 18/183 [00:02<00:22,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7721,  0.7944,  0.9130,  ...,  0.6831,  0.6386,  0.5941],\n",
      "        [ 0.8685,  0.4310,  0.6980,  ...,  0.8908,  0.6164,  0.7870],\n",
      "        [ 0.2975, -0.0437,  0.0082,  ..., -0.0437, -0.1624, -0.3329],\n",
      "        ...,\n",
      "        [-0.0808, -0.1920, -0.1327,  ...,  0.0527, -0.0659, -0.0511],\n",
      "        [-0.0659,  0.0750,  0.0898,  ...,  0.0156,  0.0676,  0.0824],\n",
      "        [-0.3181, -0.2884, -0.2662,  ..., -0.2365, -0.2439, -0.3107]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[1.0243, 1.2023, 1.1949,  ..., 0.7128, 0.8685, 0.8389],\n",
      "        [0.8315, 1.3580, 1.2171,  ..., 0.9205, 0.9650, 0.8166],\n",
      "        [0.4606, 0.6831, 0.5793,  ..., 0.4384, 0.3790, 0.4161],\n",
      "        ...,\n",
      "        [0.4903, 0.4606, 0.6015,  ..., 0.6238, 0.5941, 0.5793],\n",
      "        [0.3642, 0.2381, 0.3197,  ..., 0.5125, 0.5645, 0.4458],\n",
      "        [0.4161, 0.4458, 0.4680,  ..., 0.8240, 0.6980, 0.6831]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11%|█         | 20/183 [00:02<00:21,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3354, -2.3799, -2.3577,  ..., -0.4145,  0.4087,  0.7944],\n",
      "        [-3.1958, -3.3293, -3.4776,  ..., -2.6321, -2.8768, -2.7433],\n",
      "        [-2.9213, -2.7137, -2.5208,  ..., -1.9349, -1.4529, -0.3255],\n",
      "        ...,\n",
      "        [ 0.0453,  0.0527, -0.0289,  ...,  0.0453,  0.0972,  0.1046],\n",
      "        [ 0.1491,  0.1491,  0.0824,  ...,  0.1491,  0.1936,  0.1862],\n",
      "        [ 0.1121,  0.0824,  0.0305,  ...,  0.0527,  0.0305,  0.0824]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-0.2810, -0.0437,  0.1046,  ..., -0.6593, -0.4368, -0.2365],\n",
      "        [-2.3503, -2.5357, -2.3948,  ..., -2.2316, -2.1426, -2.1278],\n",
      "        [-0.2365, -0.1253, -0.1253,  ...,  0.0527, -0.1104,  0.0972],\n",
      "        ...,\n",
      "        [ 0.2604,  0.2975,  0.3790,  ...,  0.2381,  0.3642,  0.3345],\n",
      "        [ 0.2011,  0.2381,  0.2381,  ...,  0.1269,  0.1714,  0.2678],\n",
      "        [ 0.0453,  0.1714,  0.3049,  ...,  0.7721,  0.7202,  0.7425]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  12%|█▏        | 22/183 [00:03<00:21,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.7885e-02,  8.2188e-03, -7.3364e-02,  ...,  3.0469e-02,\n",
      "          8.2188e-03, -1.1045e-01],\n",
      "        [ 9.5754e-01,  1.2394e+00,  9.6496e-01,  ...,  1.1207e+00,\n",
      "          8.5371e-01,  8.6113e-01],\n",
      "        [ 7.4988e-01,  8.0921e-01,  8.3146e-01,  ...,  1.1281e+00,\n",
      "          1.1504e+00,  1.2468e+00],\n",
      "        ...,\n",
      "        [ 7.4968e-02,  9.7218e-02,  3.7885e-02,  ...,  1.0463e-01,\n",
      "          8.9801e-02,  8.0218e-04],\n",
      "        [ 2.5297e-01,  1.9363e-01,  1.3430e-01,  ...,  7.4968e-02,\n",
      "          1.1205e-01,  1.1205e-01],\n",
      "        [ 6.3863e-01,  5.2738e-01,  3.7905e-01,  ...,  6.2380e-01,\n",
      "          6.1638e-01,  5.5705e-01]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-3.0697, -3.0178, -2.8768,  ..., -3.0548, -3.1661, -2.9881],\n",
      "        [-3.4257, -3.2551, -3.3738,  ..., -3.2403, -3.4776, -3.5221],\n",
      "        [-2.1352, -1.9498, -1.7569,  ..., -1.5270, -0.9411, -0.6593],\n",
      "        ...,\n",
      "        [ 0.1343,  0.2011,  0.1491,  ...,  0.2530,  0.3197,  0.3494],\n",
      "        [ 0.2455,  0.2900,  0.2159,  ...,  0.3568,  0.3939,  0.3642],\n",
      "        [-0.9114, -0.7038, -0.7038,  ..., -0.6964, -0.8966, -1.0672]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  13%|█▎        | 24/183 [00:03<00:21,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7276, 0.8611, 0.9872,  ..., 0.7721, 0.7276, 0.7795],\n",
      "        [0.7425, 0.8092, 0.9798,  ..., 1.1133, 0.9427, 0.9650],\n",
      "        [0.1343, 0.2159, 0.0824,  ..., 0.0453, 0.2085, 0.2678],\n",
      "        ...,\n",
      "        [0.6238, 0.5793, 0.7054,  ..., 0.6905, 0.7350, 0.6386],\n",
      "        [0.6757, 0.6312, 0.6757,  ..., 0.5793, 0.6015, 0.7425],\n",
      "        [0.4161, 0.4087, 0.5719,  ..., 0.7944, 0.7202, 0.8389]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-2.1723, -1.8088, -1.0449,  ..., -2.4986, -2.5505, -2.7063],\n",
      "        [-2.5950, -2.5653, -2.7730,  ..., -3.1809, -3.2996, -2.6469],\n",
      "        [ 0.1417,  0.1195,  0.1491,  ...,  0.2233,  0.2826,  0.2085],\n",
      "        ...,\n",
      "        [ 0.4384,  0.4013,  0.4680,  ...,  0.6757,  0.6980,  0.6164],\n",
      "        [ 0.5719,  0.6164,  0.6090,  ...,  0.6015,  0.5570,  0.4977],\n",
      "        [ 0.3197,  0.0676, -0.0214,  ...,  0.7721,  0.8834,  0.6535]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14%|█▍        | 26/183 [00:03<00:21,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4161,  0.7870,  0.9798,  ...,  0.6090,  0.8463,  0.7573],\n",
      "        [ 0.3865,  0.1714,  0.4977,  ...,  0.5051,  0.6386,  0.8018],\n",
      "        [ 0.3716,  0.6312,  0.5422,  ...,  0.5348,  0.7128,  0.7425],\n",
      "        ...,\n",
      "        [ 0.2678, -0.0363,  0.1417,  ...,  0.3568,  0.6238,  0.4087],\n",
      "        [ 0.1195,  0.2604,  0.0156,  ...,  0.3049,  0.2752,  0.5719],\n",
      "        [ 0.7054,  0.7573,  0.6164,  ...,  0.6015,  0.5719,  0.7054]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[1.1059, 0.9130, 0.9872,  ..., 0.9872, 1.0465, 1.1059],\n",
      "        [0.9501, 1.1800, 1.3061,  ..., 0.5645, 0.4532, 1.1355],\n",
      "        [0.6460, 0.6386, 0.6980,  ..., 0.8166, 0.6015, 0.5200],\n",
      "        ...,\n",
      "        [0.8166, 0.8315, 0.8018,  ..., 0.5051, 0.5570, 0.4680],\n",
      "        [0.8611, 0.8982, 0.8463,  ..., 0.6090, 0.5645, 0.6015],\n",
      "        [0.7795, 0.7054, 0.6164,  ..., 0.1269, 0.2233, 0.0972]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  15%|█▌        | 28/183 [00:03<00:20,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.5346e-01,  8.0179e-01,  2.3813e-01,  ...,  7.4988e-01,\n",
      "          7.1280e-01,  8.1663e-01],\n",
      "        [ 1.4693e+00,  1.4396e+00,  1.6621e+00,  ...,  1.4619e+00,\n",
      "          1.3951e+00,  1.4767e+00],\n",
      "        [ 9.7238e-01,  9.9463e-01,  9.2046e-01,  ..., -6.5947e-02,\n",
      "          3.5680e-01,  5.8671e-01],\n",
      "        ...,\n",
      "        [-7.3364e-02, -4.3697e-02, -1.0303e-01,  ..., -1.4011e-01,\n",
      "         -1.7720e-01, -8.8197e-02],\n",
      "        [-4.3697e-02, -1.9945e-01, -9.5614e-02,  ..., -1.2528e-01,\n",
      "         -1.2528e-01, -2.8864e-02],\n",
      "        [ 8.0218e-04, -4.3697e-02, -7.3364e-02,  ..., -3.6281e-02,\n",
      "         -7.3364e-02, -7.3364e-02]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.8092,  0.7350,  0.9279,  ...,  1.0169,  0.7944,  0.9427],\n",
      "        [ 0.7425,  0.5200,  0.4458,  ...,  0.6386,  0.6609,  0.6757],\n",
      "        [ 0.6238,  0.4755,  0.5274,  ...,  0.5125,  0.6460,  0.5793],\n",
      "        ...,\n",
      "        [-0.2143, -0.2884, -0.8669,  ...,  0.0601,  0.0750,  0.0750],\n",
      "        [-2.6692, -2.5579, -1.1414,  ...,  0.1491,  0.2678,  0.2233],\n",
      "        [ 0.2530,  0.3420,  0.3790,  ...,  0.3420,  0.3049,  0.2900]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  16%|█▋        | 30/183 [00:04<00:20,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1949,  1.0614,  1.2913,  ...,  0.4161,  0.2900, -0.0808],\n",
      "        [ 0.9056,  1.0169,  0.9798,  ...,  0.5200,  0.5348,  0.6015],\n",
      "        [ 0.9427,  0.9353,  0.4384,  ..., -1.0969, -1.0375, -1.0820],\n",
      "        ...,\n",
      "        [ 0.7054,  0.7350,  0.6164,  ...,  0.6386,  0.6980,  0.8018],\n",
      "        [ 0.6386,  0.7499,  0.5422,  ...,  0.7202,  0.7795,  0.7276],\n",
      "        [ 0.3939,  0.3790,  0.3716,  ...,  0.3568,  0.3716,  0.3790]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[0.9353, 0.8092, 0.9650,  ..., 1.0540, 1.0169, 0.9650],\n",
      "        [0.8982, 0.6905, 0.7350,  ..., 1.0020, 1.0836, 1.2320],\n",
      "        [0.7425, 0.8982, 0.8685,  ..., 0.5941, 0.7202, 0.8240],\n",
      "        ...,\n",
      "        [0.7944, 0.8018, 0.7721,  ..., 0.5719, 0.5867, 0.6015],\n",
      "        [0.8611, 0.8685, 0.9130,  ..., 0.8834, 0.7573, 0.6905],\n",
      "        [0.6609, 0.5941, 0.6535,  ..., 0.3716, 0.3494, 0.2826]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  17%|█▋        | 32/183 [00:04<00:20,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8092,  0.8611,  1.0910,  ...,  0.9575,  0.8240,  0.9130],\n",
      "        [ 0.7128,  0.8092,  0.8685,  ...,  0.6757,  0.7647,  0.7795],\n",
      "        [ 0.7795,  0.8166,  0.9130,  ...,  0.6015,  0.5793,  0.4606],\n",
      "        ...,\n",
      "        [ 0.3049,  0.3716,  0.3865,  ...,  0.3716,  0.4161,  0.4235],\n",
      "        [ 0.1714,  0.1936,  0.3568,  ...,  0.1714,  0.1714,  0.1343],\n",
      "        [-0.6667, -0.5629, -0.6741,  ...,  0.0527,  0.0527,  0.1046]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 1.1133,  0.9427,  1.0317,  ...,  0.8908,  0.9946,  0.9056],\n",
      "        [-2.8027, -1.7495, -1.8237,  ...,  0.9946,  1.0614,  1.1133],\n",
      "        [ 0.5496,  0.7276,  0.8463,  ...,  0.6460, -0.4145, -1.4751],\n",
      "        ...,\n",
      "        [-0.0437, -0.1179,  0.0082,  ...,  0.0601,  0.0527, -0.1920],\n",
      "        [ 0.0527,  0.0156,  0.0972,  ...,  0.1640,  0.1714,  0.2011],\n",
      "        [ 0.0527, -0.0289, -0.0289,  ..., -0.3255, -0.2810, -0.3033]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  19%|█▊        | 34/183 [00:04<00:19,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0585,  0.0527, -0.1030,  ...,  0.0082, -0.1624, -0.2217],\n",
      "        [ 0.2900,  0.2900,  0.4829,  ...,  0.5422,  0.5051,  0.5867],\n",
      "        [ 0.5496,  0.3568,  0.4087,  ...,  0.4606,  0.8092,  0.6090],\n",
      "        ...,\n",
      "        [ 0.7499,  0.8389,  0.9056,  ...,  0.6831,  0.7054,  0.6460],\n",
      "        [ 0.8092,  0.8685,  0.8463,  ...,  0.7054,  0.6980,  0.7276],\n",
      "        [ 0.8611,  0.8240,  0.7870,  ...,  0.5867,  0.6312,  0.6164]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-2.3725, -2.3873, -2.2983,  ...,  0.3642,  0.2678,  0.1936],\n",
      "        [ 0.2381,  0.3271,  0.3420,  ...,  0.2752,  0.2604,  0.1936],\n",
      "        [-1.3119, -1.0746, -0.7557,  ..., -0.0363,  0.0082,  0.0231],\n",
      "        ...,\n",
      "        [ 0.7276,  0.7721,  0.8685,  ...,  0.7054,  0.6015,  0.6757],\n",
      "        [ 0.7350,  0.8685,  0.8982,  ...,  0.8018,  0.6831,  0.7425],\n",
      "        [ 0.6460,  0.7499,  0.7202,  ...,  0.4903,  0.4161,  0.3420]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  20%|█▉        | 36/183 [00:05<00:19,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.9055e-01,  7.0538e-01,  6.6830e-01,  ...,  7.4988e-01,\n",
      "          5.9413e-01,  5.4963e-01],\n",
      "        [ 1.4841e+00,  1.4545e+00,  1.3877e+00,  ...,  1.4100e+00,\n",
      "          1.3655e+00,  1.3358e+00],\n",
      "        [ 5.1996e-01,  4.0130e-01,  5.9413e-01,  ...,  8.8338e-01,\n",
      "          8.8338e-01,  9.4271e-01],\n",
      "        ...,\n",
      "        [ 5.2718e-02,  1.5635e-02,  3.0469e-02,  ..., -8.8197e-02,\n",
      "         -4.3697e-02,  7.4968e-02],\n",
      "        [ 8.9801e-02,  2.3052e-02, -6.6144e-03,  ..., -6.6144e-03,\n",
      "          8.2188e-03,  8.0218e-04],\n",
      "        [ 2.7522e-01,  1.7880e-01,  3.0488e-01,  ...,  2.6780e-01,\n",
      "          2.2330e-01,  2.6780e-01]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.9056,  0.8760,  0.7944,  ...,  0.8982,  0.8389,  0.8760],\n",
      "        [-3.2551, -3.1068, -2.5505,  ...,  0.6609,  0.8018,  0.9575],\n",
      "        [-0.2217, -0.1327, -0.1104,  ...,  0.1714,  0.1417,  0.2159],\n",
      "        ...,\n",
      "        [ 0.7276,  0.7202,  0.7202,  ...,  0.5941,  0.6238,  0.6312],\n",
      "        [ 0.6460,  0.7128,  0.7054,  ...,  0.6460,  0.7054,  0.6683],\n",
      "        [ 0.4458,  0.4829,  0.4977,  ...,  0.4606,  0.4458,  0.4606]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  21%|██        | 38/183 [00:05<00:19,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9872,  1.0688,  1.1281,  ...,  0.9205,  0.9056,  0.8760],\n",
      "        [ 0.3123,  0.6238,  1.1133,  ...,  0.9353,  1.0465,  0.9353],\n",
      "        [-0.3626, -0.2365,  0.2085,  ...,  0.4532,  0.2678,  0.3939],\n",
      "        ...,\n",
      "        [ 0.1121,  0.1640,  0.1269,  ..., -0.0066, -0.0511, -0.0437],\n",
      "        [ 0.2678,  0.2604,  0.2233,  ...,  0.0527,  0.0898,  0.0305],\n",
      "        [ 0.1936,  0.2011,  0.2085,  ...,  0.1788,  0.1640,  0.0972]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-2.6692, -2.7063, -2.7137,  ..., -2.7063, -2.7211, -2.6988],\n",
      "        [ 0.8018,  1.0169,  1.0391,  ...,  0.8685,  0.7276,  0.7276],\n",
      "        [-2.3280, -2.2761, -1.8237,  ..., -1.7347, -1.8385, -2.1723],\n",
      "        ...,\n",
      "        [ 0.1269, -0.0289,  0.1046,  ...,  0.1121, -0.0659,  0.0750],\n",
      "        [ 0.0231,  0.2455,  0.1640,  ...,  0.1862,  0.0898,  0.0379],\n",
      "        [ 0.3271,  0.3420,  0.3123,  ...,  0.3197,  0.1788,  0.0453]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  22%|██▏       | 40/183 [00:05<00:18,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4912, -2.5653, -2.5653,  ..., -2.3206, -2.3354, -2.3651],\n",
      "        [-3.3367, -3.0474, -2.7137,  ..., -2.8917, -3.1290, -3.0623],\n",
      "        [ 0.0231,  0.0898, -0.0289,  ..., -0.1475, -0.0882, -0.0289],\n",
      "        ...,\n",
      "        [ 0.6683,  0.6460,  0.5125,  ...,  0.6905,  0.7128,  0.7276],\n",
      "        [ 0.6609,  0.6312,  0.6015,  ...,  0.7870,  0.6905,  0.5496],\n",
      "        [ 0.6238,  0.6980,  0.7276,  ...,  0.7202,  0.6831,  0.6905]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-2.6098, -2.6173, -2.7211,  ..., -2.3354, -2.5431, -2.1797],\n",
      "        [-3.3367, -3.4702, -3.4702,  ..., -3.5517, -3.4034, -3.4183],\n",
      "        [ 0.3271,  0.5051,  0.5200,  ...,  0.5867,  0.5496,  0.5867],\n",
      "        ...,\n",
      "        [-0.0140, -0.0659, -0.1401,  ..., -0.0363, -0.0659, -0.0882],\n",
      "        [ 0.1343,  0.0676, -0.0214,  ...,  0.1195,  0.0527,  0.0824],\n",
      "        [-0.4294, -0.2662, -0.2143,  ..., -1.1784, -1.0820, -1.0746]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  23%|██▎       | 42/183 [00:05<00:18,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1574, -2.2168, -2.0610,  ..., -2.5653, -2.5283, -2.5653],\n",
      "        [-2.7508, -2.8027, -2.8027,  ..., -3.2180, -3.2625, -3.3812],\n",
      "        [ 0.0453, -0.3997, -0.8002,  ...,  0.1121,  0.1862,  0.3271],\n",
      "        ...,\n",
      "        [ 0.5348,  0.7054,  0.6460,  ...,  0.6609,  0.6386,  0.6609],\n",
      "        [ 0.5422,  0.6386,  0.5867,  ...,  0.6460,  0.7425,  0.6980],\n",
      "        [ 0.3568,  0.3790,  0.3716,  ...,  0.3939,  0.4087,  0.3939]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 3.7885e-02,  1.1205e-01,  6.7552e-02,  ..., -5.8531e-02,\n",
      "          8.0218e-04,  1.0463e-01],\n",
      "        [ 6.9796e-01,  9.3529e-01,  7.4246e-01,  ...,  5.3480e-01,\n",
      "          5.1255e-01,  4.3838e-01],\n",
      "        [ 3.1972e-01,  4.9030e-01,  4.4580e-01,  ...,  3.5680e-01,\n",
      "          4.3838e-01,  3.8647e-01],\n",
      "        ...,\n",
      "        [-5.8531e-02, -1.5495e-01, -1.8461e-01,  ..., -2.8864e-02,\n",
      "         -2.1448e-02,  4.5302e-02],\n",
      "        [ 8.0218e-04, -1.1786e-01, -3.6281e-02,  ...,  1.0463e-01,\n",
      "          1.2688e-01,  1.4913e-01],\n",
      "        [ 2.3813e-01,  2.2330e-01,  1.6397e-01,  ..., -5.1114e-02,\n",
      "         -2.8864e-02, -2.1448e-02]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  24%|██▍       | 44/183 [00:06<00:18,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9130, 0.9798, 0.9946,  ..., 0.9798, 0.9724, 1.0540],\n",
      "        [0.5348, 0.6460, 0.7350,  ..., 0.9056, 0.7795, 0.8908],\n",
      "        [0.7944, 0.6831, 0.7647,  ..., 1.1652, 1.2616, 1.2839],\n",
      "        ...,\n",
      "        [0.7425, 0.8092, 0.7795,  ..., 0.6683, 0.6312, 0.5200],\n",
      "        [0.7573, 0.8018, 0.8092,  ..., 0.7870, 0.6015, 0.5570],\n",
      "        [0.4755, 0.4606, 0.4087,  ..., 0.1936, 0.1936, 0.1788]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-2.8027, -2.6543, -2.3725,  ..., -2.5060, -2.6173, -2.6247],\n",
      "        [-2.6469, -2.2464, -2.3725,  ..., -3.2254, -3.2996, -3.1216],\n",
      "        [-1.1043, -1.1488, -1.4751,  ..., -1.7866, -1.7050, -1.6902],\n",
      "        ...,\n",
      "        [-0.2217, -0.1104,  0.0601,  ...,  0.1269,  0.1491,  0.1343],\n",
      "        [ 0.2455,  0.1862,  0.2381,  ...,  0.1640,  0.1417,  0.0601],\n",
      "        [ 0.4235,  0.4606,  0.4235,  ...,  0.4532,  0.4087,  0.4161]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25%|██▌       | 46/183 [00:06<00:17,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5629, -0.3478, -0.2217,  ...,  0.4310,  0.4087,  0.2085],\n",
      "        [ 0.2307,  0.2233,  0.2900,  ...,  0.4087,  0.3494,  0.3642],\n",
      "        [-0.4145, -0.5184, -0.5629,  ..., -0.3107, -0.1104, -0.1253],\n",
      "        ...,\n",
      "        [ 0.2011,  0.2752,  0.2826,  ...,  0.5422,  0.5867,  0.5496],\n",
      "        [ 0.2900,  0.3790,  0.4087,  ...,  0.6980,  0.6831,  0.6015],\n",
      "        [-1.2971, -0.8521, -0.7112,  ..., -0.6148, -0.3329, -0.4071]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.6312,  0.6238,  0.6460,  ...,  0.7128,  0.6683,  0.6164],\n",
      "        [ 1.4322,  1.3729,  1.4025,  ...,  1.3951,  1.4025,  1.4322],\n",
      "        [ 0.5719,  0.6238,  0.8463,  ...,  0.9501,  0.7202,  0.8685],\n",
      "        ...,\n",
      "        [-0.1104, -0.1549, -0.0734,  ..., -0.0214, -1.0153, -1.3935],\n",
      "        [ 0.1788,  0.1491,  0.0824,  ...,  0.2900,  0.2752,  0.3642],\n",
      "        [-0.2736, -0.1030, -0.1327,  ..., -0.5258, -0.5925, -0.7854]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  26%|██▌       | 48/183 [00:06<00:17,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3725, -2.2316, -2.2168,  ..., -2.6247, -2.4541, -2.4170],\n",
      "        [-2.3725, -2.6098, -2.6321,  ..., -3.1216, -2.9362, -3.2180],\n",
      "        [-1.4751, -1.5789, -1.7273,  ..., -1.6902, -1.6383, -1.4751],\n",
      "        ...,\n",
      "        [ 0.4977,  0.5274,  0.5719,  ...,  0.4458,  0.4977,  0.4680],\n",
      "        [ 0.4755,  0.6090,  0.7276,  ...,  0.4013,  0.5200,  0.4903],\n",
      "        [ 0.8018,  0.6905,  0.7128,  ...,  0.7795,  0.7350, -0.0734]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-2.6395, -2.7063, -2.6024,  ..., -2.8101, -2.8472, -2.7730],\n",
      "        [-3.3738, -3.4924, -3.4702,  ..., -3.6556, -3.4183, -3.4850],\n",
      "        [-0.3255, -0.1401, -0.2959,  ...,  0.0750,  0.0082, -0.1994],\n",
      "        ...,\n",
      "        [-0.0956, -0.0511, -0.0140,  ..., -0.0511, -0.1401, -0.1401],\n",
      "        [ 0.1195,  0.0972,  0.1195,  ...,  0.0156, -0.0511,  0.0082],\n",
      "        [ 0.0156,  0.0601, -0.0363,  ..., -0.0956, -0.0734, -0.0437]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  27%|██▋       | 50/183 [00:06<00:17,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1945, -2.1055, -1.9720,  ..., -1.8533, -1.9423, -1.9275],\n",
      "        [-0.1994,  0.1121,  0.1936,  ...,  0.3271,  0.3642,  0.3568],\n",
      "        [-1.4751, -1.2452, -1.3194,  ...,  0.5793,  0.4235,  0.2381],\n",
      "        ...,\n",
      "        [ 0.6164,  0.7054,  0.6535,  ...,  0.6386,  0.6090,  0.4755],\n",
      "        [ 0.6090,  0.6535,  0.6535,  ...,  0.6757,  0.6164,  0.5793],\n",
      "        [ 0.5570,  0.6386,  0.6386,  ...,  0.7870,  0.7425,  0.6683]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[0.4458, 0.5274, 0.5125,  ..., 0.7350, 0.6238, 0.4606],\n",
      "        [1.1504, 1.1800, 1.0391,  ..., 1.4174, 1.4693, 1.6250],\n",
      "        [0.8240, 0.9724, 0.9575,  ..., 0.7647, 0.8018, 0.8463],\n",
      "        ...,\n",
      "        [0.5200, 0.6386, 0.6609,  ..., 0.7128, 0.7054, 0.6757],\n",
      "        [0.3494, 0.5570, 0.6312,  ..., 0.5422, 0.6683, 0.6980],\n",
      "        [0.6386, 0.6460, 0.5793,  ..., 0.6238, 0.6609, 0.5793]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  28%|██▊       | 52/183 [00:07<00:18,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6386,  0.5941,  0.6386,  ...,  0.5570,  0.5200,  0.5867],\n",
      "        [ 1.4322,  1.3358,  1.4470,  ..., -2.1129, -1.7347, -1.5048],\n",
      "        [-0.8892, -0.5925, -0.5925,  ..., -1.7273, -1.6308, -1.4084],\n",
      "        ...,\n",
      "        [ 0.7276,  0.6460,  0.7721,  ...,  0.6609,  0.6238,  0.6460],\n",
      "        [ 0.5125,  0.5422,  0.5645,  ...,  0.5200,  0.5348,  0.5793],\n",
      "        [ 0.6386,  0.6980,  0.8092,  ...,  0.1862,  0.2307,  0.2085]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.1343,  0.0601, -0.0140,  ..., -0.0734, -0.1327, -0.1624],\n",
      "        [ 1.4322,  1.1875,  0.9130,  ...,  0.9650,  1.2023,  1.0836],\n",
      "        [ 0.4161,  0.5793,  0.4384,  ...,  0.8315,  0.9501,  0.7721],\n",
      "        ...,\n",
      "        [ 0.0898,  0.1491,  0.1269,  ...,  0.2530,  0.2678,  0.3420],\n",
      "        [ 0.2159,  0.1936,  0.2233,  ...,  0.3865,  0.3939,  0.4087],\n",
      "        [-0.9263, -0.5480, -0.6370,  ..., -0.8892, -0.7779, -0.6519]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  29%|██▉       | 53/183 [00:07<00:17,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11400, 9])\n",
      "tensor([[-3.4183, -3.2773, -2.9510,  ..., -3.5592, -3.2773, -2.7730],\n",
      "        [-0.3478, -0.0659, -0.0808,  ..., -0.0585, -0.0214, -0.1253],\n",
      "        [-1.2155, -0.5703, -0.3033,  ..., -0.1772, -0.1846, -0.0956],\n",
      "        ...,\n",
      "        [ 0.5422,  0.4161,  0.1566,  ...,  0.0972,  0.3494,  0.2011],\n",
      "        [ 0.4161,  0.5348,  0.1491,  ...,  0.1417,  0.0676,  0.2975],\n",
      "        [ 0.8166,  0.8908,  0.9056,  ...,  0.8018,  0.6312,  0.6015]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  30%|███       | 55/183 [00:07<00:19,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8546, -3.0178, -2.8027,  ..., -2.0462, -0.7779, -0.0956],\n",
      "        [-3.2551, -3.3218, -3.3960,  ..., -3.1958, -3.2922, -3.0178],\n",
      "        [ 0.4903,  0.6238,  0.6238,  ...,  0.6535,  0.6312,  0.5348],\n",
      "        ...,\n",
      "        [ 0.2381,  0.3049,  0.2900,  ...,  0.2975,  0.2455,  0.2455],\n",
      "        [ 0.3790,  0.4161,  0.4532,  ...,  0.3049,  0.3420,  0.1121],\n",
      "        [-0.0734, -0.0214,  0.0898,  ...,  0.4235,  0.4903,  0.5125]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-3.0252, -3.2180, -3.2403,  ..., -2.6840, -2.7063, -2.8620],\n",
      "        [-3.7001, -3.6778, -3.3367,  ..., -3.6482, -3.6185, -3.5443],\n",
      "        [ 0.2530,  0.1491,  0.2530,  ...,  0.5125,  0.5051,  0.4755],\n",
      "        ...,\n",
      "        [ 0.2159,  0.3271,  0.4013,  ...,  0.2307,  0.2604,  0.3271],\n",
      "        [ 0.2826,  0.2085,  0.2159,  ...,  0.2381,  0.3049,  0.2975],\n",
      "        [-2.0462, -1.4232, -1.7718,  ..., -0.0289, -0.1104, -0.0511]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  31%|███       | 56/183 [00:07<00:23,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.7721,  0.8240,  0.7202,  ...,  0.8463,  0.6535,  0.4606],\n",
      "        [ 1.4396,  1.5731,  1.4174,  ...,  1.5064,  1.4470,  1.5286],\n",
      "        [ 0.9872,  0.9724,  1.0688,  ...,  0.9353,  0.7573,  0.8315],\n",
      "        ...,\n",
      "        [-0.0437,  0.0527, -0.1994,  ...,  0.4903,  0.5125,  0.2975],\n",
      "        [ 0.1343, -0.3997,  0.0527,  ...,  0.0676,  0.2604,  0.1714],\n",
      "        [ 0.6238,  0.6460,  0.6905,  ...,  0.6980,  0.6609,  0.7128]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  31%|███       | 57/183 [00:08<00:22,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11400, 9])\n",
      "tensor([[ 1.1355,  0.9056,  0.7202,  ...,  0.6312,  0.7573,  0.6683],\n",
      "        [ 0.1269,  0.7647,  0.7870,  ...,  0.4458,  0.5941,  0.5719],\n",
      "        [ 0.5348,  0.4977,  0.6090,  ...,  0.6980,  0.8315,  0.7944],\n",
      "        ...,\n",
      "        [ 0.1491,  0.0824,  0.0898,  ..., -0.1030, -0.0140,  0.0972],\n",
      "        [ 0.2381,  0.2604,  0.3123,  ...,  0.0379,  0.1417,  0.2307],\n",
      "        [ 0.1862,  0.1788,  0.1714,  ...,  0.2011,  0.1936,  0.0972]])\n",
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  32%|███▏      | 59/183 [00:08<00:22,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7721, 0.7425, 0.7721,  ..., 0.9798, 0.8166, 0.8685],\n",
      "        [0.4680, 0.7202, 0.5570,  ..., 0.8315, 0.9798, 0.9872],\n",
      "        [0.4384, 0.4532, 0.6535,  ..., 0.6164, 0.8166, 0.8315],\n",
      "        ...,\n",
      "        [0.5274, 0.7128, 0.6905,  ..., 0.8389, 0.7573, 0.7499],\n",
      "        [0.5422, 0.7499, 0.6831,  ..., 0.8389, 0.8389, 0.3939],\n",
      "        [0.6090, 0.7647, 0.8463,  ..., 0.6312, 0.6609, 0.6609]])\n",
      "torch.Size([11400, 9])\n",
      "tensor([[-0.0214, -0.1920, -0.2143,  ..., -1.4974, -1.7050, -1.9498],\n",
      "        [ 0.5570,  0.3568, -0.2217,  ..., -2.5208, -2.5802, -2.8694],\n",
      "        [-0.8224, -0.8744, -0.6593,  ..., -0.2069, -0.3255, -0.4368],\n",
      "        ...,\n",
      "        [ 0.7054,  0.7128,  0.5793,  ...,  0.6015,  0.7350,  0.6980],\n",
      "        [ 0.5348,  0.5422,  0.4977,  ...,  0.6831,  0.7425,  0.7721],\n",
      "        [ 0.6164,  0.6980,  0.5941,  ...,  0.2307,  0.2381,  0.3568]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|███▎      | 60/183 [00:08<00:22,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11400, 9])\n",
      "tensor([[ 0.2233,  0.1417,  0.1640,  ...,  0.5051,  0.5645,  0.1417],\n",
      "        [ 0.3420,  0.3494,  0.2381,  ...,  0.2455,  0.3642,  0.2455],\n",
      "        [-1.4454, -1.4529, -1.2823,  ..., -1.5270, -1.1339, -1.3045],\n",
      "        ...,\n",
      "        [ 0.8537,  0.8240,  0.6238,  ...,  0.7573,  0.8389,  0.7944],\n",
      "        [ 0.8018,  0.6980,  0.8092,  ...,  0.7870,  0.8092,  0.7944],\n",
      "        [ 0.6460,  0.5348,  0.7054,  ...,  0.7647,  0.6312,  0.6238]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|███▎      | 61/183 [00:08<00:17,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m model_train(train_dataloader, val_dataloader, config, device)\n",
      "Cell \u001b[0;32mIn[25], line 31\u001b[0m, in \u001b[0;36mmodel_train\u001b[0;34m(train_dataloader, val_dataloader, config, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# For every epoch, train the model on training dataset. Evaluate model on validation dataset\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config[\u001b[39m'\u001b[39m\u001b[39mEPOCHS\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m---> 31\u001b[0m     loss \u001b[39m=\u001b[39m train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n\u001b[1;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[39], line 56\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, dataloader, optimizer, loss_fn, epoch)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mEvaluation function to evaluate model on data\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39m:param model Model to evaluate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m:param epoch Current epoch\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 56\u001b[0m \u001b[39mfor\u001b[39;00m _, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(dataloader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m     57\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     58\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/torch_geometric/loader/dataloader.py:19\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m elem \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m Batch\u001b[39m.\u001b[39;49mfrom_data_list(batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfollow_batch,\n\u001b[1;32m     20\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexclude_keys)\n\u001b[1;32m     21\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/torch_geometric/data/batch.py:76\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_data_list\u001b[39m(\u001b[39mcls\u001b[39m, data_list: List[BaseData],\n\u001b[1;32m     66\u001b[0m                    follow_batch: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m                    exclude_keys: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     batch, slice_dict, inc_dict \u001b[39m=\u001b[39m collate(\n\u001b[1;32m     77\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m     78\u001b[0m         data_list\u001b[39m=\u001b[39;49mdata_list,\n\u001b[1;32m     79\u001b[0m         increment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     80\u001b[0m         add_batch\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data_list[\u001b[39m0\u001b[39;49m], Batch),\n\u001b[1;32m     81\u001b[0m         follow_batch\u001b[39m=\u001b[39;49mfollow_batch,\n\u001b[1;32m     82\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49mexclude_keys,\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     85\u001b[0m     batch\u001b[39m.\u001b[39m_num_graphs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[1;32m     86\u001b[0m     batch\u001b[39m.\u001b[39m_slice_dict \u001b[39m=\u001b[39m slice_dict\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/torch_geometric/data/collate.py:84\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m value, slices, incs \u001b[39m=\u001b[39m _collate(attr, values, data_list, stores,\n\u001b[1;32m     85\u001b[0m                                increment)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mis_cuda:\n\u001b[1;32m     88\u001b[0m     device \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/torch_geometric/data/collate.py:135\u001b[0m, in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    133\u001b[0m     incs \u001b[39m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m incs\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mint\u001b[39m(incs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m         values \u001b[39m=\u001b[39m [\n\u001b[1;32m    136\u001b[0m             value \u001b[39m+\u001b[39m inc\u001b[39m.\u001b[39mto(value\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    137\u001b[0m             \u001b[39mfor\u001b[39;00m value, inc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(values, incs)\n\u001b[1;32m    138\u001b[0m         ]\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     incs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/.STGATenv/lib/python3.9/site-packages/torch_geometric/data/collate.py:136\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    133\u001b[0m     incs \u001b[39m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m incs\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mint\u001b[39m(incs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m         values \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 136\u001b[0m             value \u001b[39m+\u001b[39;49m inc\u001b[39m.\u001b[39;49mto(value\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    137\u001b[0m             \u001b[39mfor\u001b[39;00m value, inc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(values, incs)\n\u001b[1;32m    138\u001b[0m         ]\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     incs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_train(train_dataloader, val_dataloader, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df194c1-5d8c-4013-8e01-13535415fba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "708971fd-a566-4d45-8116-12472f8dc224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0985, 0.9798, 1.0095,  ..., 0.8834, 0.8315, 0.6980],\n",
      "        [0.8685, 1.0465, 1.0169,  ..., 0.7202, 0.7795, 0.8240],\n",
      "        [0.8611, 0.8240, 0.6683,  ..., 0.6905, 0.5793, 0.6312],\n",
      "        ...,\n",
      "        [0.6386, 0.6164, 0.5719,  ..., 0.6609, 0.6535, 0.7350],\n",
      "        [0.6460, 0.6609, 0.6831,  ..., 0.6905, 0.7054, 0.7721],\n",
      "        [0.6831, 0.6905, 0.7054,  ..., 0.8389, 0.8389, 0.8611]])\n",
      "torch.Size([27, 11400, 9])\n",
      "tensor([[ 0.6609,  0.6238,  0.9575,  ...,  1.0243,  0.8611,  0.9650],\n",
      "        [ 0.5719,  0.6609,  0.7647,  ...,  0.7795,  0.6683,  0.6238],\n",
      "        [ 0.6312,  0.6386,  0.8092,  ...,  0.8463,  0.8908,  0.9205],\n",
      "        ...,\n",
      "        [ 0.2307,  0.3494,  0.2604,  ...,  0.2307,  0.2085,  0.1491],\n",
      "        [ 0.2752, -0.8299, -1.3787,  ..., -0.0659,  0.0601,  0.0379],\n",
      "        [-0.0066,  0.2233,  0.2085,  ...,  0.0972,  0.1195,  0.2900]])\n",
      "tensor([[-2.5134, -2.3725, -2.4986,  ..., -2.4912, -2.6098, -2.7730],\n",
      "        [ 0.7425,  0.7795,  0.8240,  ...,  0.5719,  0.5570,  0.4829],\n",
      "        [-1.7495, -2.0388, -1.7569,  ..., -1.6457, -1.5196, -1.2378],\n",
      "        ...,\n",
      "        [ 0.1269,  0.1046,  0.0527,  ...,  0.0082,  0.0082,  0.0898],\n",
      "        [ 0.1195,  0.1121,  0.2085,  ...,  0.0379,  0.0750,  0.0750],\n",
      "        [ 0.1121,  0.1862,  0.1195,  ..., -0.0066, -0.1030, -0.2439]])\n",
      "tensor([[-6.2961e-01, -2.2170e-01,  1.5635e-02,  ..., -3.1811e-01,\n",
      "         -2.8864e-02,  2.9005e-01],\n",
      "        [-5.9253e-01, -5.4061e-01, -1.0894e+00,  ..., -2.4244e+00,\n",
      "         -2.4244e+00, -2.5283e+00],\n",
      "        [-1.9868e+00, -1.7347e+00, -1.6086e+00,  ..., -3.8486e-01,\n",
      "         -4.2936e-01, -5.4061e-01],\n",
      "        ...,\n",
      "        [ 1.1205e-01,  8.0218e-04,  8.9801e-02,  ...,  3.4938e-01,\n",
      "          2.9005e-01,  2.6038e-01],\n",
      "        [ 1.0463e-01,  2.2330e-01,  2.5297e-01,  ...,  3.9388e-01,\n",
      "          2.7522e-01,  3.3455e-01],\n",
      "        [-8.6694e-01, -1.0153e+00, -8.2986e-01,  ..., -1.2600e+00,\n",
      "         -1.4084e+00, -1.0820e+00]])\n",
      "tensor([[-2.6173e+00, -2.5876e+00, -2.6988e+00,  ...,  9.7218e-02,\n",
      "          5.0513e-01,  5.7188e-01],\n",
      "        [-3.3144e+00, -3.3812e+00, -3.3812e+00,  ..., -3.3070e+00,\n",
      "         -3.3070e+00, -3.3070e+00],\n",
      "        [ 4.6805e-01,  4.0872e-01,  5.7188e-01,  ...,  4.2355e-01,\n",
      "          5.3480e-01,  4.6063e-01],\n",
      "        ...,\n",
      "        [ 3.2713e-01,  3.4938e-01,  3.1972e-01,  ...,  5.7188e-01,\n",
      "          5.8671e-01,  5.5705e-01],\n",
      "        [ 2.0105e-01,  1.5635e-02,  8.0218e-04,  ...,  3.7163e-01,\n",
      "          3.3455e-01,  3.5680e-01],\n",
      "        [ 1.4913e-01,  4.0130e-01,  3.9388e-01,  ...,  9.4271e-01,\n",
      "          8.1663e-01,  7.3505e-01]])\n",
      "tensor([[ 0.6535,  0.5570,  0.7870,  ...,  0.7350,  0.7795,  0.8018],\n",
      "        [ 0.6460,  0.7425,  0.7573,  ...,  0.6460,  0.6460,  0.5422],\n",
      "        [ 0.4087,  0.4532,  0.5200,  ...,  0.7202,  0.6683,  0.5496],\n",
      "        ...,\n",
      "        [ 0.5274,  0.6386,  0.5941,  ...,  0.6460,  0.7054,  0.7425],\n",
      "        [ 0.4310,  0.5570,  0.6757,  ...,  0.5867,  0.6831, -0.0511],\n",
      "        [ 0.4680,  0.3865,  0.3790,  ...,  0.5051,  0.4977,  0.5200]])\n",
      "tensor([[ 0.5348,  0.7202,  0.7870,  ...,  0.9130,  1.0020,  0.9427],\n",
      "        [ 0.6980,  0.7350,  0.9946,  ...,  0.7573,  0.5645,  0.9575],\n",
      "        [ 0.6905,  0.7425,  0.5125,  ...,  0.6831,  0.6535,  0.6831],\n",
      "        ...,\n",
      "        [ 0.4087,  0.4680,  0.2604,  ...,  0.2678,  0.1788,  0.1343],\n",
      "        [ 0.5496,  0.2752,  0.3345,  ...,  0.3716,  0.3123,  0.3123],\n",
      "        [-0.5035, -0.7409, -0.6148,  ..., -0.0140,  0.0305, -0.0140]])\n",
      "tensor([[-0.9634, -0.8818, -0.4442,  ..., -2.2464, -2.4689, -2.6173],\n",
      "        [ 0.6015,  0.6905,  0.6535,  ...,  0.8092,  0.7425,  0.6460],\n",
      "        [-1.3119, -1.4751, -1.2971,  ..., -1.9201, -1.6383, -1.8163],\n",
      "        ...,\n",
      "        [-0.1772, -0.0511,  0.0824,  ..., -0.1401, -0.0437,  0.0231],\n",
      "        [ 0.1046,  0.1046,  0.0231,  ..., -0.0289,  0.1566,  0.1566],\n",
      "        [ 0.2085,  0.1195,  0.2455,  ...,  0.1046,  0.1714,  0.1343]])\n",
      "tensor([[ 4.5302e-02,  1.3430e-01, -9.4852e-01,  ..., -1.7792e+00,\n",
      "         -1.0894e+00, -2.7361e-01],\n",
      "        [ 1.8622e-01,  2.1588e-01,  1.9363e-01,  ..., -1.1339e+00,\n",
      "         -8.5211e-01, -1.6160e+00],\n",
      "        [-1.1636e+00, -1.1191e+00, -1.0227e+00,  ..., -4.7386e-01,\n",
      "         -5.7028e-01, -4.3678e-01],\n",
      "        ...,\n",
      "        [-3.4036e-01, -1.8461e-01, -1.8461e-01,  ...,  8.0218e-04,\n",
      "          6.0135e-02,  8.2385e-02],\n",
      "        [-1.2528e-01, -2.1448e-02,  3.7885e-02,  ..., -1.4031e-02,\n",
      "          8.9801e-02,  1.1947e-01],\n",
      "        [-1.4753e-01, -1.9945e-01, -3.3294e-01,  ..., -1.6978e-01,\n",
      "         -1.6236e-01, -2.3653e-01]])\n",
      "tensor([[-2.5950e+00, -2.5728e+00, -2.4541e+00,  ..., -2.9288e+00,\n",
      "         -2.7359e+00, -2.5357e+00],\n",
      "        [-2.9658e+00, -3.0548e+00, -3.0623e+00,  ..., -3.1290e+00,\n",
      "         -3.3738e+00, -3.3960e+00],\n",
      "        [-1.6978e-01, -5.1114e-02, -6.6144e-03,  ..., -5.2578e-01,\n",
      "         -3.6281e-02,  2.9747e-01],\n",
      "        ...,\n",
      "        [ 2.7522e-01,  3.1972e-01,  3.5680e-01,  ...,  2.4555e-01,\n",
      "          2.0847e-01,  1.4172e-01],\n",
      "        [ 2.0105e-01,  1.4172e-01,  1.7138e-01,  ..., -1.0303e-01,\n",
      "          8.0218e-04,  2.0847e-01],\n",
      "        [-1.0004e+00, -9.1144e-01, -5.1836e-01,  ...,  3.3455e-01,\n",
      "          3.4197e-01,  3.5680e-01]])\n",
      "tensor([[ 0.9798,  0.8760,  0.8982,  ...,  0.6609,  0.7425,  0.7499],\n",
      "        [-2.5802, -2.5060, -2.6321,  ...,  0.7425,  0.8537,  0.8611],\n",
      "        [ 0.6090,  0.6757,  0.7870,  ...,  0.8982,  0.7350,  0.6535],\n",
      "        ...,\n",
      "        [ 0.8166,  0.7573,  0.7499,  ...,  0.7128,  0.6535,  0.6757],\n",
      "        [ 0.5051,  0.7350,  0.5348,  ...,  0.5570,  0.5941,  0.6831],\n",
      "        [ 0.7425,  0.6980,  0.6015,  ...,  0.4903,  0.5719,  0.5348]])\n",
      "tensor([[0.7573, 0.8685, 0.8463,  ..., 0.8018, 1.0688, 0.8537],\n",
      "        [0.8389, 0.7870, 0.7128,  ..., 0.4087, 0.1491, 0.3642],\n",
      "        [0.8463, 0.8092, 0.6460,  ..., 0.7499, 0.7499, 0.7425],\n",
      "        ...,\n",
      "        [0.7202, 0.6831, 0.7944,  ..., 0.6980, 0.6386, 0.5496],\n",
      "        [0.7870, 0.8240, 0.7721,  ..., 0.6980, 0.7202, 0.6831],\n",
      "        [0.7054, 0.7647, 0.8092,  ..., 0.6980, 0.6386, 0.5570]])\n",
      "tensor([[ 0.9872,  1.1652,  1.0688,  ...,  0.7128,  0.4680,  0.5645],\n",
      "        [ 0.8389,  0.6312,  0.6980,  ...,  0.5793,  0.4310,  0.3197],\n",
      "        [ 0.7944,  0.8685,  0.6312,  ..., -0.3700, -0.5035, -0.9485],\n",
      "        ...,\n",
      "        [-0.0289, -0.0585, -0.0437,  ..., -0.0140, -0.1253, -0.1104],\n",
      "        [-0.0511, -0.0882, -0.1327,  ..., -0.0585,  0.0750, -0.0214],\n",
      "        [ 0.2381,  0.1566,  0.2011,  ..., -0.0585, -0.0289, -0.0956]])\n",
      "tensor([[-2.3206, -2.3799, -2.3354,  ..., -1.9423, -1.8014, -1.7569],\n",
      "        [ 0.3420,  0.2604,  0.2975,  ...,  0.1491,  0.2233,  0.4013],\n",
      "        [-1.6679, -1.6383, -1.2897,  ..., -1.7198, -1.6605, -1.4084],\n",
      "        ...,\n",
      "        [-0.0289, -0.0363, -0.1179,  ..., -0.2810, -0.1624, -0.0511],\n",
      "        [-0.0437, -0.0289, -0.1179,  ..., -0.2291, -0.0289, -0.0289],\n",
      "        [-0.1475, -0.0808, -0.0140,  ..., -0.2959, -0.2514, -0.1846]])\n",
      "tensor([[ 3.4197e-01,  4.0130e-01,  1.3430e-01,  ..., -7.2602e-01,\n",
      "         -1.1339e+00, -1.0524e+00],\n",
      "        [ 8.2385e-02,  2.0847e-01,  8.9801e-02,  ..., -2.3799e+00,\n",
      "         -2.4244e+00, -2.3873e+00],\n",
      "        [ 8.0218e-04,  2.3052e-02, -4.3697e-02,  ...,  2.3052e-02,\n",
      "         -8.0780e-02, -2.6620e-01],\n",
      "        ...,\n",
      "        [ 4.9030e-01,  4.2355e-01,  3.7163e-01,  ...,  1.9363e-01,\n",
      "          2.5297e-01,  2.1588e-01],\n",
      "        [ 4.7546e-01,  4.5321e-01,  4.2355e-01,  ...,  2.1588e-01,\n",
      "          1.1205e-01,  1.1947e-01],\n",
      "        [-9.0402e-01, -8.6694e-01, -9.4111e-01,  ..., -7.4086e-01,\n",
      "         -6.4444e-01, -5.7028e-01]])\n",
      "tensor([[-2.9510, -3.0029, -2.9362,  ..., -0.8002,  0.0898,  0.5200],\n",
      "        [-3.6037, -3.5147, -3.5369,  ..., -3.2032, -3.3070, -3.2254],\n",
      "        [ 0.5125,  0.5274,  0.2826,  ...,  0.5051,  0.5200,  0.5570],\n",
      "        ...,\n",
      "        [ 0.5125,  0.5274,  0.4235,  ...,  0.6312,  0.7573,  0.6905],\n",
      "        [ 0.4829,  0.5719,  0.3568,  ...,  0.6535,  0.7573,  0.7647],\n",
      "        [ 0.8982,  0.9130,  0.8834,  ...,  1.0095,  0.9501,  0.9501]])\n",
      "tensor([[ 0.7350,  0.6980,  0.8018,  ...,  0.6757,  0.6683,  0.6460],\n",
      "        [ 0.9946,  1.0243,  0.8982,  ...,  0.6905,  0.8611,  0.7276],\n",
      "        [-0.2736,  0.2307,  0.5348,  ...,  0.7425,  0.6757,  0.7054],\n",
      "        ...,\n",
      "        [ 0.6757,  0.8018,  0.7721,  ...,  0.6980,  0.5719,  0.6905],\n",
      "        [ 0.7202,  0.6905,  0.7425,  ...,  0.6015,  0.5348,  0.6757],\n",
      "        [ 0.6905,  0.6980,  0.6831,  ...,  0.6980,  0.8463,  0.8389]])\n",
      "tensor([[ 0.8092,  0.6831,  0.8908,  ...,  1.0762,  0.9724,  1.0985],\n",
      "        [ 0.7202,  0.5645,  0.4680,  ...,  0.9724,  0.7795,  0.8240],\n",
      "        [ 0.4755,  0.6831,  0.4384,  ...,  1.0762,  0.9946,  0.9427],\n",
      "        ...,\n",
      "        [-0.0882, -0.1475, -0.0659,  ...,  0.2011,  0.1862,  0.1269],\n",
      "        [-1.0672, -0.3552, -0.3404,  ...,  0.2085,  0.1343,  0.1714],\n",
      "        [-1.2600, -0.8076, -0.6519,  ...,  0.4235,  0.2530,  0.1566]])\n",
      "tensor([[-2.8398, -2.8694, -2.8472,  ..., -2.6840, -2.6543, -2.6766],\n",
      "        [ 1.0465,  0.9798,  0.8389,  ...,  0.7647,  0.6831,  0.8685],\n",
      "        [-2.5505, -2.7656, -2.6914,  ..., -2.0388, -1.8978, -1.7718],\n",
      "        ...,\n",
      "        [-0.0659, -0.1401, -0.0140,  ...,  0.0676,  0.0601,  0.0601],\n",
      "        [ 0.0453, -0.1475, -0.1624,  ...,  0.1491,  0.0601,  0.0601],\n",
      "        [ 0.0527,  0.1566,  0.1936,  ..., -0.0585, -0.0066,  0.0305]])\n",
      "tensor([[-1.6234, -0.8002, -0.5406,  ..., -0.1327,  0.2455,  0.3123],\n",
      "        [-1.1710, -1.7940, -2.2464,  ..., -2.6098, -2.6988, -2.6618],\n",
      "        [-1.9720, -2.0907, -1.6902,  ..., -1.2823, -0.9411, -0.8818],\n",
      "        ...,\n",
      "        [ 0.2307,  0.1269, -0.2588,  ...,  0.1714,  0.2159,  0.2159],\n",
      "        [ 0.3345, -0.1179, -0.1846,  ...,  0.3049,  0.3568,  0.2975],\n",
      "        [-2.1426, -1.4084, -1.5864,  ..., -0.0437, -0.2736, -1.1117]])\n",
      "tensor([[-2.7433e+00, -2.8472e+00, -2.8917e+00,  ..., -3.0029e+00,\n",
      "         -2.8546e+00, -2.9510e+00],\n",
      "        [-3.6852e+00, -3.6852e+00, -3.5369e+00,  ..., -3.3886e+00,\n",
      "         -3.4183e+00, -3.3886e+00],\n",
      "        [ 2.0847e-01,  1.0463e-01,  8.0218e-04,  ...,  7.4968e-02,\n",
      "         -5.1114e-02, -2.9586e-01],\n",
      "        ...,\n",
      "        [ 8.9801e-02,  1.4913e-01,  8.9801e-02,  ...,  3.6422e-01,\n",
      "          1.8622e-01,  2.7522e-01],\n",
      "        [ 3.0469e-02,  8.2385e-02,  1.3430e-01,  ...,  3.0469e-02,\n",
      "          1.4172e-01,  9.7218e-02],\n",
      "        [ 4.7546e-01,  4.6063e-01,  4.5321e-01,  ...,  5.7930e-01,\n",
      "          4.4580e-01,  4.2355e-01]])\n",
      "tensor([[0.8166, 0.8760, 0.8834,  ..., 0.4903, 0.5051, 0.5570],\n",
      "        [0.7944, 0.8315, 0.7202,  ..., 0.4903, 0.5941, 0.5496],\n",
      "        [0.6312, 0.4532, 0.5793,  ..., 0.7054, 0.7870, 0.7573],\n",
      "        ...,\n",
      "        [0.4903, 0.3123, 0.2900,  ..., 0.5570, 0.6164, 0.6164],\n",
      "        [0.3790, 0.2159, 0.5496,  ..., 0.6535, 0.6460, 0.5719],\n",
      "        [0.3197, 0.3123, 0.3123,  ..., 0.4384, 0.5125, 0.4829]])\n",
      "tensor([[ 1.4248,  1.1800,  1.2097,  ...,  0.9130,  0.8018,  0.8685],\n",
      "        [ 1.0910,  0.8315,  0.7795,  ...,  0.6386,  0.7944,  0.8092],\n",
      "        [ 0.6312,  0.7944,  0.6609,  ...,  0.5422,  0.5200,  0.6312],\n",
      "        ...,\n",
      "        [ 0.5200,  0.4829,  0.5051,  ...,  0.3345,  0.2159,  0.1936],\n",
      "        [ 0.6460,  0.5941,  0.6164,  ...,  0.4977,  0.4977,  0.4087],\n",
      "        [ 0.4013,  0.1046,  0.1566,  ...,  0.0305, -0.0882, -0.0734]])\n",
      "tensor([[-0.3552, -0.6593, -0.6519,  ..., -1.0227, -0.9930, -0.9856],\n",
      "        [ 0.5125,  0.5348,  0.5719,  ...,  0.6164,  0.6460,  0.7054],\n",
      "        [-1.2007, -1.2304, -1.2526,  ..., -0.4368, -0.7631, -1.2600],\n",
      "        ...,\n",
      "        [-0.1401, -0.0659, -0.0437,  ..., -0.1772, -0.1253, -0.2143],\n",
      "        [ 0.0305, -0.0214,  0.0379,  ..., -0.1401, -0.0956, -0.1475],\n",
      "        [ 0.1121,  0.0305, -0.0882,  ...,  0.1195,  0.2530,  0.3197]])\n",
      "tensor([[-2.5060e+00, -2.4986e+00, -2.6988e+00,  ..., -1.7421e+00,\n",
      "         -1.8904e+00, -2.0610e+00],\n",
      "        [-1.7792e+00, -1.7940e+00, -2.1278e+00,  ..., -2.4689e+00,\n",
      "         -2.3132e+00, -2.3651e+00],\n",
      "        [-1.1191e+00, -9.9302e-01, -8.1502e-01,  ..., -1.0524e+00,\n",
      "         -8.1502e-01, -1.2304e+00],\n",
      "        ...,\n",
      "        [-2.2835e+00, -2.4244e+00, -2.2983e+00,  ..., -2.0388e+00,\n",
      "         -2.0981e+00, -2.2168e+00],\n",
      "        [ 6.0135e-02,  2.3052e-02,  8.0218e-04,  ...,  1.4172e-01,\n",
      "          6.0135e-02,  6.0135e-02],\n",
      "        [-1.7720e-01, -2.5136e-01, -1.5495e-01,  ..., -4.8128e-01,\n",
      "         -4.3678e-01, -2.5136e-01]])\n",
      "tensor([[-3.1513, -2.9436, -2.7953,  ..., -3.0474, -2.8249, -2.9584],\n",
      "        [-2.7137, -3.0178, -3.2922,  ..., -3.6037, -3.6556, -3.6852],\n",
      "        [-0.4739, -0.5258, -0.1920,  ...,  0.0453, -0.5406, -0.8447],\n",
      "        ...,\n",
      "        [ 0.4384,  0.3939,  0.3345,  ...,  0.4087,  0.3568,  0.2233],\n",
      "        [ 0.5570,  0.5274,  0.5867,  ...,  0.5570,  0.4087,  0.4384],\n",
      "        [-0.4368, -0.4294, -0.1772,  ...,  0.3939,  0.4013,  0.5125]])\n",
      "tensor([[ 1.0614,  1.2171,  1.0762,  ...,  0.8982,  0.8834,  1.0540],\n",
      "        [-2.0462, -0.3478,  0.4161,  ...,  1.0614,  0.8982,  0.8166],\n",
      "        [ 0.5496,  0.6312,  0.6905,  ...,  0.4087,  0.4532,  0.5348],\n",
      "        ...,\n",
      "        [ 0.6905,  0.7202,  0.5867,  ...,  0.5719,  0.6535,  0.7202],\n",
      "        [ 0.6609,  0.5793,  0.6090,  ...,  0.5867,  0.6460,  0.6757],\n",
      "        [-2.7063, -2.8175, -2.7433,  ..., -2.8323, -2.9139, -2.9658]])\n",
      "Test, MAE: 9.831183433532715, RMSE: 13.130069732666016, MAPE: 28.060279846191406\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_prediction(test_dataloader, y_pred, y_truth, node, config):\n",
    "    # Calculate the truth\n",
    "    s = y_truth.shape\n",
    "    y_truth = y_truth.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
    "    # just get the first prediction out for the nth node\n",
    "    y_truth = y_truth[:, :, node, 0]\n",
    "    # Flatten to get the predictions for entire test dataset\n",
    "    y_truth = torch.flatten(y_truth)\n",
    "    day0_truth = y_truth[:config['N_SLOT']]\n",
    "\n",
    "\n",
    "    # Calculate the predicted\n",
    "    s = y_pred.shape\n",
    "    y_pred = y_pred.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
    "    # just get the first prediction out for the nth node\n",
    "    y_pred = y_pred[:, :, node, 0]\n",
    "    # Flatten to get the predictions for entire test dataset\n",
    "    y_pred = torch.flatten(y_pred)\n",
    "    # Just grab the first day\n",
    "    day0_pred = y_pred[:config['N_SLOT']]\n",
    "    t = [t for t in range(0, config['N_SLOT']*5, 5)]\n",
    "    plt.plot(t, day0_pred, label='ST-GAT')\n",
    "    plt.plot(t, day0_truth, label='truth')\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.ylabel('Speed prediction')\n",
    "    plt.title('Predictions of traffic over time')\n",
    "    plt.legend()\n",
    "    plt.savefig('predicted_times.png')\n",
    "    plt.show()\n",
    "    \n",
    "_, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n",
    "\n",
    "plot_prediction(test_dataloader, y_pred, y_truth, 0, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
